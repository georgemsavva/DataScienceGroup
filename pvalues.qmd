---
title: Data Science Group Notes
format: 
  gfm:
    output-file: README.md
---

# Introduction

This file supports a presentation for the QIB Data Science group in June 2023

# Exploring the garden of forking paths

If I want to look at the implications of a particular statistical procedure I will often simulate some data with known properties and then test how well I can recover them.

Here I will look at the effect of trying lots of different analyses on the same dataset.

Suppose we will be testing whether $y$ depends on $x$ in a small observational dataset of men and women.  We'll also measure a covariate $z$.

We will use a linear regression model, but will test the implications of different design choices on the validity of the analysis.

```{r oneSimulation}

# Set the dataset size
N = 20

# Here is a dataset in which Y does not depend on X.
df <- data.frame(
  X = rnorm(N),  # The predictor of interest.
  Z = rnorm(N),  # Covariate
  Sex = rep(c("M","F"),each=N/2),  # Sex of participant
  Y = rnorm(N)   # The outcome.  We know it is not influenced by the predictor.
)

# Check the dataset.
df

# Analysis 1 - linear regression for X on Y.
# Tidyverse way
pvalue1 <- lm(data=df , Y~X) |> 
  broom::tidy() |> 
  dplyr::pull(p.value) |> 
  purrr::pluck(2)  # There has got to be an easier way to do this.

# Or the old way
model1  <- lm(data=df, Y~X)
pvalue1 <- coef(summary(model1))["X", "Pr(>|t|)"]

# What should the p-value be?
pvalue1

```

To see if the regression model is working OK, we should look at the distribution over repeated experiments.

We know that 5% of p-values should be less than p=0.05. 10% should be less than 0.1 etc....

To check this, we encase the previous code in a function, and then use `replicate` to repeat it:

```{r }

oneRep <- function(N=20){
  
  # New data
  df <- data.frame(
    X = rnorm(N),  # The predictor of interest.
    Z = rnorm(N),  # Covariate
    Sex = rep(c("M","F"),each=N/2),  # Sex of participant
    Y = rnorm(N)   # The outcome.  We know it is not influenced by the predictor.
  )
  # Return the p-value
  coef(summary(lm(data=df, Y~X)))["X", "Pr(>|t|)"]
  
}

pvalues <- replicate(1000 , oneRep(20))

hist(pvalues , breaks=20)

```

What happens if we adjust for the covariate in the model.

```{r }

oneRep <- function(N=20){
  
  # New data
  df <- data.frame(
    X = rnorm(N),  # The predictor of interest.
    Z = rnorm(N),  # Covariate
    Sex = rep(c("M","F"),each=N/2),  # Sex of participant
    Y = rnorm(N)   # The outcome.  We know it is not influenced by the predictor.
  )
  # Return the p-value
  coef(summary(lm(data=df, Y~X+Z)))["X", "Pr(>|t|)"]
  
}

pvalues <- replicate(1000 , oneRep(20))

hist(pvalues , breaks=20)

```

So both models look OK.  They both have the same false positive rate, and it's correct.

Which one is correct?

Now what happens if we can run either model or a model with sex as an additional covariate, and choose the one that works the best.

```{r  }

oneRep <- function(N=20){
  
  # New data
  df <- data.frame(
    X = rnorm(N),  # The predictor of interest.
    Z = rnorm(N),  # Covariate
    Sex = rep(c("M","F"),each=N/2),  # Sex of participant
    Y = rnorm(N)   # The outcome.  We know it is not influenced by the predictor.
  )

  # Apply models and p-value extraction to two different formulas
  pvalues <- list( Y~X , Y~X+Z , Y~X+Z+Sex ) |> 
    lapply(lm, data=df) |> 
    sapply(\(m) coef(summary(m))["X", "Pr(>|t|)"] )
  
}

oneRep()

pvalues <- replicate(1000 , oneRep(20)) |> apply(2, min)

hist(pvalues , breaks=20)

```

What is the type-1 error rate of this procedure?

```{r }
100 * mean(pvalues<0.05)
```

Finally, what else could we do?

Subgroup analyses (men vs women vs all), remove 'outliers' or not (>2 sds from zero).  How many different analyses do we have now?

```{r }
oneRep <- function(N=20){
  
  # New data
  df <- data.frame(
    X = rnorm(N),  # The predictor of interest.
    Z = rnorm(N),  # Covariate
    Sex = rep(c("M","F"),each=N/2),  # Sex of participant
    Y = rnorm(N)   # The outcome.  We know it is not influenced by the predictor.
  )
  
  df2 <- df[abs(df$Y)<2,]
  
  ## We have six different datasets we could use
  dfs <- c(list(df, df2),
            split(df ,  df$Sex), 
            split(df2 , df2$Sex))
  
  ## Three models to apply to each.
  lapply(dfs , \(d){
  list( Y~X , Y~X+Z  ) |> 
    lapply(lm, data=d) |> 
    sapply(\(m) coef(summary(m))["X", "Pr(>|t|)"] )
    }) |> unlist()
  
}

pvalues <- replicate(1000 , oneRep(20)) |> apply(2, min)

hist(pvalues , breaks=20)


```



So for 1 in 5 studies there is an analysis with p<0.05, even with no relationship.  So a 20% type 1 error rate.  And this assumes that 

None of these models were unreasonable, we could easily and justifiably use any one.

What do you do in your own work?


# Subgroup analysis 1

Here I want to set up a situation where subgroups are apparently inconsistent even though the effect is the same in each group.

```{r }
library(ggplot2)
library(emmeans)
library(patchwork)

N=50
set.seed(11)
df <- data.frame(
    X = rep(c("Trt","Ctrl"), N/2),  # The treatment (predictor of interest)
    Z = rnorm(N),  # Covariate
    Sex = rep(c("M","F"),each=N/2)  # Sex of participant
    )
df$Y = rnorm(N)+ifelse(df$X=="Trt",.5,0)   # The outcome.  We know it is influenced by the predictor, but this is not affected by sex.

model3 <- lm(Y~X*Sex, data=df)
model4 <- lm(Y~X, data=df)

```

So we've estimated two models, one where the effect of X depends on sex and one where it does not.

```{r }

# No evidence for an interaction effect.
anova(model3, model4)

emmeans(model3 , pairwise ~ X | Sex , infer=c(TRUE, TRUE) )$contrast
emmeans(model4 , pairwise ~ X , infer=c(TRUE, TRUE) )$contrast

plot1 <- emmeans(model3 , pairwise ~ X | Sex , infer=c(TRUE, TRUE) )$contrast |> 
  data.frame() |>
  ggplot() + 
  aes(Sex, estimate, ymin=lower.CL, ymax=upper.CL ) + 
  geom_pointrange() + coord_flip() + theme_bw() + geom_hline(yintercept=0)+ 
  lims(y=c(-2,0.6))

plot2 <- emmeans(model4 , pairwise ~ X , infer=c(TRUE, TRUE) )$contrast |> 
  data.frame() |>
  ggplot() + 
  aes(x= "Overall", estimate, ymin=lower.CL, ymax=upper.CL ) + 
  geom_pointrange() + coord_flip() + theme_bw() + geom_hline(yintercept=0) + 
  lims(y=c(-2,0.6))

plot1 / plot2 + plot_layout(heights=c(2,1))

anova(model3)



```
